---
tags:
  - TV
  - social_media
  - children
skills: 
layout: default
edited_date: 
title: I'm disappointed with "Swiped"
previous_in_series:
---
If you live in the UK there is a good chance that you have heard about the Channel 4 documentary/social experiment thing *Swiped* where they relieve a bunch of kids of their phones for 3 weeks. If you haven't then maybe read this [*Guardian* article](https://www.theguardian.com/tv-and-radio/2024/dec/11/swiped-the-school-that-banned-smartphones-review-channel-4).

I finally got round to watching it and I'm a bit disappointed really. To put it plainly, the show focuses on the phones rather that social media and other harmful websites. They even visit families of children who died as a result of these platforms but instead of naming and shaming they instead blame the phones.

This is a massive missed opportunity to turn public opinion against these multinational corporations, who know that they cause harm to everybody, not just children and yet continue anyway.

They seem to do this in order to argue for a smartphone ban for children when, as anyone who has been through the secondary school system in England recently will know, the ban would never work. 

The modern schooling system requires students to have access to their own device through a [Bring Your Own Device (BYOD) policy](https://hwb.gov.wales/support-centre/education-digital-standards/bring-your-own-device-guidance/) - the secondary that I attended would even lend devices to people if they couldn't afford one. If children where banned from owning smartphones, they would continue to use social media on whatever other device they own. Often these are Chromebooks, which can install Android apps so it is *very* easy.

The only way that I can see of reducing the harm that social media (and similar things) cause to children is to reduce the harm that it causes everybody indiscriminately. There is no real way of knowing if anyone is a
n adult online so laws targeting just children are ineffective. We just need social media to be better.

We know that they can do this - Facebook has ["break the glass" measures](https://www.techpolicy.press/we-know-a-little-about-metas-break-glass-measures-we-should-know-more/) that decrease hate speech, misinformation and graphic violence on the site. Why are they not always in place? Money, and because no one is making them do it.

I don't think that it is a stretch to say that its likely that other social media algorithms could be changed in similar ways. 
We need to *make them do it*, because they are not going to do it themselves.
